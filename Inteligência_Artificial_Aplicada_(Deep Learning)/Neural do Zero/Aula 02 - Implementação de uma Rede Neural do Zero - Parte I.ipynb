{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e43aec5-2171-4fd6-8402-22ab5100f763",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Segunda atividade de programação\n",
    "\n",
    "No código que se segue, você deverá completar as partes indicadas.\n",
    "\n",
    "Note que o código está construído em OOP (Orientação ao Objeto), usando classes e métodos.\n",
    "\n",
    "Leitura recomendada:\n",
    "\n",
    "https://docs.microsoft.com/pt-br/learn/modules/python-object-oriented-programming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f93a8c4-c0fd-4dc4-a142-19c8dc5655cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Callable, Optional, TypeVar, Tuple\n",
    "from functools import reduce\n",
    "from random import random\n",
    "from math import exp\n",
    "from random import shuffle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b341ca-49fc-4d28-a8c4-c9ab4199f12c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funções auxiliares\n",
    "\n",
    "def dot_product(xs: List[float], ys: List[float]) -> float:\n",
    "    return sum(x * y for x, y in zip(xs, ys))\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    return 1.0/(1.0 + exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x: float) -> float:\n",
    "    sig: float = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def normalize(dataset: List[List[float]]) -> None:\n",
    "    for col_num in range(len(dataset[0])):\n",
    "        column: List[float] = [row[col_num] for row in dataset]\n",
    "        maximum: float = max(column)\n",
    "        minimum: float = min(column)\n",
    "        for row_num in range(len(dataset)):\n",
    "            dataset[row_num][col_num] = (dataset[row_num][col_num] - minimum) / (maximum - minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08aa32d3-21ce-4f87-8e4e-2f601a82c0f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, weights: List[float], learning_rate: float,\n",
    "    activation_function: Callable[[float], float],\n",
    "    derivative_activation_function: Callable[[float], float]) -> None:\n",
    "        self.weights: List[float] = weights\n",
    "        self.activation_function: Callable[[float], float] = activation_function\n",
    "        self.derivative_activation_function: Callable[[float], float] = \\\n",
    "            derivative_activation_function\n",
    "        self.learning_rate: float = learning_rate\n",
    "        self.output_cache: float = 0.0\n",
    "        self.delta: float = 0.0\n",
    "\n",
    "    def output(self, inputs: List[float]) -> float:\n",
    "        self.output_cache = dot_product(inputs, self.weights)\n",
    "        return self.activation_function(self.output_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96db7cd-136d-41dc-91d4-d8872a3b6d2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, previous_layer: Optional[Layer], num_neurons: int,\n",
    "    learning_rate: float, activation_function: Callable[[float], float],\n",
    "    derivative_activation_function: Callable[[float], float]) -> None:\n",
    "        self.previous_layer: Optional[Layer] = previous_layer\n",
    "        self.neurons: List[Neuron] = []\n",
    "        # following could all be one large list comprehension\n",
    "        for i in range(num_neurons):\n",
    "            if previous_layer is None:\n",
    "                random_weights: List[float] = []\n",
    "            else:\n",
    "                random_weights = [random() for _ in range(len(previous_layer.neurons))]\n",
    "            neuron: Neuron = Neuron(random_weights, learning_rate,\n",
    "            activation_function, derivative_activation_function)\n",
    "            self.neurons.append(neuron)\n",
    "        self.output_cache: List[float] = [0.0 for _ in range(num_neurons)]\n",
    "\n",
    "    def outputs(self, inputs: List[float]) -> List[float]:\n",
    "        if self.previous_layer is None:\n",
    "            self.output_cache = inputs\n",
    "        else:\n",
    "            self.output_cache = [n.output(inputs) for n in self.neurons]\n",
    "        return self.output_cache\n",
    "\n",
    "    # should only be called on output layer\n",
    "    def calculate_deltas_for_output_layer(self, expected: List[float]) -> None:\n",
    "        for n in range(len(self.neurons)):\n",
    "            self.neurons[n].delta = self.neurons[n].derivative_activation_function(self.neurons[n].output_cache) \\\n",
    "                * (expected[n] - self.output_cache[n])\n",
    "\n",
    "    # should not be called on output layer\n",
    "    def calculate_deltas_for_hidden_layer(self, next_layer: Layer) -> None:\n",
    "        for index, neuron in enumerate(self.neurons):\n",
    "            next_weights: List[float] = [n.weights[index] for n in next_layer.neurons]\n",
    "            next_deltas: List[float] = [n.delta for n in next_layer.neurons]\n",
    "            sum_weights_and_deltas: float = dot_product(next_weights, next_deltas)\n",
    "            neuron.delta = neuron.derivative_activation_function(neuron.output_cache) * sum_weights_and_deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262656ac-7cb0-4af7-b504-56d2f9587530",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Agora que temos uma implementação tanto do neurônio, quanto da camada, podemos passar para a construção da rede em si.\n",
    "\n",
    "- A rede é apenas uma informação de estado: as camadas que ela administra.\n",
    "- Abaixo temos uma classe `Network` que é responsável por inicializar as camadas que a compõem.\n",
    "- O método `__init__()` aceita uma lista de `ints` que descreve a estrutura da rede.\n",
    "> Exemplo: [2, 4, 2] descreve uma rede com 2 neurônios em sua camada de entrada, 4 na cama da oculta e 3 na de saída.\n",
    "- Vamos assumir que todas as camadas irão usar a mesma função de ativação.\n",
    "\n",
    "**Obs**: `T = TypeVar(T)` indica que qualquer tipo de dados é aceitável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c4ba1c-3e8a-4faf-a950-1887a7d2565d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layer_structure: List[int], learning_rate: float, \n",
    "                 activation_function: Callable[[float], float]=sigmoid,\n",
    "                 derivative_activation_function: Callable[[float], float]=derivative_sigmoid) -> None:\n",
    "        if len(layer_structure) < 3:\n",
    "            raise ValueError(\"Error: Should be at least 3 layers: [1 input, 1 hidden, 1 output]\")\n",
    "        self.layers: List[Layer] = []\n",
    "        # Construção da rede de entrada\n",
    "        input_layer: Layer = Layer(None, layer_structure[0], learning_rate, activation_function, derivative_activation_function)\n",
    "        self.layers.append(input_layer)\n",
    "        \n",
    "        # Construção das camadas oculta e de saída\n",
    "        for previous, num_neurons in enumerate(layer_structure[1::]):\n",
    "            next_layer = Layer(self.layers[previous], num_neurons, learning_rate, activation_function, derivative_activation_function)\n",
    "            self.layers.append(next_layer)\n",
    "    \n",
    "    def outputs(self, input: List[float]) -> List[float]:\n",
    "        \"\"\" Fornece dados de entrada para a primeira camada; em seguida, a saída da primeira\n",
    "        é forneceida como entrada para a segunda, a saída da segunda para a terceira, e assim\n",
    "        segue de maneira sucessiva.\n",
    "        \"\"\"\n",
    "        return reduce(lambda inputs, layer: layer.outputs(inputs), self.layers, input)\n",
    "    \n",
    "    def backpropagate(self, expected: List[float]) -> None:\n",
    "        \"\"\"Função responsável por calcular os deltas para todos os neurônios da rede.\n",
    "        Calcula as mudanças em cada neurônio com base nos erros da saída, em comparação\n",
    "        com a saída esperada.\n",
    "        \"\"\"\n",
    "        # delta para cada neurônio da camada de saída\n",
    "        last_layer: int = len(self.layers) - 1\n",
    "        self.layers[last_layer].calculate_delas_for_out_put_layer(expected)\n",
    "        \n",
    "        # delta para as camadas ocultas, na ordem inversa\n",
    "        for l in range(last_layer - 1, 0, -1):\n",
    "            self.layers[l].calculate_deltas_for_hidden_layers(self.layers[l+1])\n",
    "    \n",
    "    def update_weights(self) -> None:\n",
    "        \"\"\"Atualiza os pesos da rede usando os resultados produzidos pelo\n",
    "        método backpropagate.\n",
    "        \"\"\"\n",
    "        for layer in self.layers[1:]: # pulamos a camada de entrada\n",
    "            for neuron in layer.neurons:\n",
    "                for w in range(len(neuron.weights)):\n",
    "                    neuron.weights[w] = neuron.weights[w] + (neuron.learning_rate * (layer.previous_layer.output_cache[w]) * neuron.delta)\n",
    "    \n",
    "    # Já temos toda a estrutura montada. O que precisamos agora são das funções para treino e validação.\n",
    "    def train(self, inputs: List[[float]], expecteds: List[[float]]) -> None:\n",
    "        \"\"\"Usa o resultado de outputs(), obtidos a partir de várias entradas e\n",
    "        comparados com expecteds, para fornecer ao backpropagete() e update_weights()\n",
    "        \"\"\"\n",
    "        for location, xs in enumerate(inputs):\n",
    "            ys: List[float] = expecteds[location]\n",
    "            outs: List[float] = self.outputs(xs)\n",
    "            self.backpropagate(ys)\n",
    "            self.update_weights()\n",
    "            \n",
    "    def validate(self, inputs: List[[float]], expecteds: List[T],\n",
    "                 interpret_output: Callable[[List[float]], T]) -> Tuple[int, int, float]:\n",
    "        \"\"\"Para resultados genéricos que exijam classificação, esta função devolve o número\n",
    "        de tentativascorretas e a percentagem delas em relação ao total.\n",
    "        \"\"\"\n",
    "        correct: int = 0\n",
    "        for input, expected in zip(inputs, expecteds):\n",
    "            result: T = interpret_output(self.outputs(input))\n",
    "            if result == expected: correct += 1\n",
    "            percentage: float = correct / len(inputs)\n",
    "            return correct, len(inputs), percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877da04a-af84-415b-b178-6b04bbe3b353",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Teste da implementação\n",
    "\n",
    "Vamos usar um dataset bem popular chamado Iris, que contem 3 diferentes classes de uma mesma flor: Iris-setosa, Iris-versicolor e  Iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9c76a1-9b4b-4f6f-b9fc-9cc249e6d846",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Layer' object has no attribute 'calculate_delas_for_out_put_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47004/586967213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0miris_trainers_corrects\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris_classifications\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0miris_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris_trainers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris_trainers_corrects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# test over the last 10 of the irises in the data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47004/783606462.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, inputs, expecteds)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mys\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpecteds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mouts\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47004/783606462.py\u001b[0m in \u001b[0;36mbackpropagate\u001b[1;34m(self, expected)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# delta para cada neurônio da camada de saída\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mlast_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_delas_for_out_put_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# delta para as camadas ocultas, na ordem inversa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Layer' object has no attribute 'calculate_delas_for_out_put_layer'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    iris_parameters: List[List[float]] = []\n",
    "    iris_classifications: List[List[float]] = []\n",
    "    iris_species: List[str] = []\n",
    "    with open('iris.csv', mode='r') as iris_file:\n",
    "        irises: List = list(csv.reader(iris_file))\n",
    "        shuffle(irises) # get our lines of data in random order\n",
    "        for iris in irises:\n",
    "            parameters: List[float] = [float(n) for n in iris[0:4]]\n",
    "            iris_parameters.append(parameters)\n",
    "            species: str = iris[4]\n",
    "            if species == \"Iris-setosa\":\n",
    "                iris_classifications.append([1.0, 0.0, 0.0])\n",
    "            elif species == \"Iris-versicolor\":\n",
    "                iris_classifications.append([0.0, 1.0, 0.0])\n",
    "            else:\n",
    "                iris_classifications.append([0.0, 0.0, 1.0])\n",
    "            iris_species.append(species)\n",
    "    normalize(iris_parameters)\n",
    "\n",
    "    iris_network: Network = Network([4, 6, 3], 0.3)\n",
    "\n",
    "    def iris_interpret_output(output: List[float]) -> str:\n",
    "        if max(output) == output[0]:\n",
    "            return \"Iris-setosa\"\n",
    "        elif max(output) == output[1]:\n",
    "            return \"Iris-versicolor\"\n",
    "        else:\n",
    "            return \"Iris-virginica\"\n",
    "\n",
    "    # train over the first 140 irises in the data set 50 times\n",
    "    iris_trainers: List[List[float]] = iris_parameters[0:140]\n",
    "    iris_trainers_corrects: List[List[float]] = iris_classifications[0:140]\n",
    "    for _ in range(50):\n",
    "        iris_network.train(iris_trainers, iris_trainers_corrects)\n",
    "\n",
    "    # test over the last 10 of the irises in the data set\n",
    "    iris_testers: List[List[float]] = iris_parameters[140:150]\n",
    "    iris_testers_corrects: List[str] = iris_species[140:150]\n",
    "    iris_results = iris_network.validate(iris_testers, iris_testers_corrects, iris_interpret_output)\n",
    "    print(f\"{iris_results[0]} correct of {iris_results[1]} = {iris_results[2] * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a2da0-ad3c-4117-9e89-90c4cdb0f81e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
