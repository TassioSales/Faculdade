{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowload_arquivos import lista_fim_links\n",
    "from dowload_arquivos import baixar_csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob as gb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy as sql\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = lista_fim_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baixando o arquivo ca-2004-01.csv\n",
      "Tamanho do arquivo: 46.38 MB\n",
      "tempo de download: 0.072961 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2004-02.csv\n",
      "Tamanho do arquivo: 150.79 MB\n",
      "tempo de download: 0.070234 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2005-01.csv\n",
      "Tamanho do arquivo: 86.81 MB\n",
      "tempo de download: 0.070449 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2005-02.csv\n",
      "Tamanho do arquivo: 121.86 MB\n",
      "tempo de download: 0.060372 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2006-01.csv\n",
      "Tamanho do arquivo: 143.31 MB\n",
      "tempo de download: 0.076448 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2006-02.csv\n",
      "Tamanho do arquivo: 131.99 MB\n",
      "tempo de download: 0.085137 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2007-01.csv\n",
      "Tamanho do arquivo: 16.44 MB\n",
      "tempo de download: 0.075557 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2007-02.csv\n",
      "Tamanho do arquivo: 108.57 MB\n",
      "tempo de download: 0.088443 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2008-01.csv\n",
      "Tamanho do arquivo: 31.25 MB\n",
      "tempo de download: 0.087372 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2008-02.csv\n",
      "Tamanho do arquivo: 112.01 MB\n",
      "tempo de download: 0.055808 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2009-01.csv\n",
      "Tamanho do arquivo: 106.42 MB\n",
      "tempo de download: 0.079988 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2009-02.csv\n",
      "Tamanho do arquivo: 80.34 MB\n",
      "tempo de download: 0.058258 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2010-01.csv\n",
      "Tamanho do arquivo: 103.56 MB\n",
      "tempo de download: 0.076261 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2010-02.csv\n",
      "Tamanho do arquivo: 25.19 MB\n",
      "tempo de download: 0.074098 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2011-01.csv\n",
      "Tamanho do arquivo: 107.64 MB\n",
      "tempo de download: 0.054647 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2011-02.csv\n",
      "Tamanho do arquivo: 107.73 MB\n",
      "tempo de download: 0.072715 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2012-01.csv\n",
      "Tamanho do arquivo: 109.98 MB\n",
      "tempo de download: 0.094382 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2012-02.csv\n",
      "Tamanho do arquivo: 10.75 MB\n",
      "tempo de download: 0.080001 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2013-01.csv\n",
      "Tamanho do arquivo: 15.81 MB\n",
      "tempo de download: 0.077538 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2013-02.csv\n",
      "Tamanho do arquivo: 116.59 MB\n",
      "tempo de download: 0.056861 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2014-01.csv\n",
      "Tamanho do arquivo: 114.24 MB\n",
      "tempo de download: 0.056125 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2014-02.csv\n",
      "Tamanho do arquivo: 9.81 MB\n",
      "tempo de download: 0.078447 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2015-01.csv\n",
      "Tamanho do arquivo: 116.19 MB\n",
      "tempo de download: 0.052668 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2015-02.csv\n",
      "Tamanho do arquivo: 68.73 MB\n",
      "tempo de download: 0.079421 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2016-01.csv\n",
      "Tamanho do arquivo: 5.44 MB\n",
      "tempo de download: 0.067311 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2016-02.csv\n",
      "Tamanho do arquivo: 81.84 MB\n",
      "tempo de download: 0.05576 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2017-01.csv\n",
      "Tamanho do arquivo: 6.81 MB\n",
      "tempo de download: 0.091316 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2017-02.csv\n",
      "Tamanho do arquivo: 50.45 MB\n",
      "tempo de download: 0.088945 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2018-01.csv\n",
      "Tamanho do arquivo: 13.31 MB\n",
      "tempo de download: 0.199415 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2018-02.csv\n",
      "Tamanho do arquivo: 82.56 MB\n",
      "tempo de download: 0.055044 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2019-01.csv\n",
      "Tamanho do arquivo: 83.15 MB\n",
      "tempo de download: 0.058173 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2019-02.csv\n",
      "Tamanho do arquivo: 84.89 MB\n",
      "tempo de download: 0.172022 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2020-01.csv\n",
      "Tamanho do arquivo: 82.64 MB\n",
      "tempo de download: 0.0537 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2020-02.csv\n",
      "Tamanho do arquivo: 37.10 MB\n",
      "tempo de download: 0.051902 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2021-01.csv\n",
      "Tamanho do arquivo: 55.23 MB\n",
      "tempo de download: 0.059564 segundos\n",
      "Arquivo salvo com sucesso!\n",
      "baixando o arquivo ca-2021-02.csv\n",
      "Tamanho do arquivo: 77.55 MB\n",
      "tempo de download: 0.097602 segundos\n",
      "Arquivo salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    "    baixar_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpar a memoria do python usando o garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar função para verificar se as colunas de cada arquivo são iguais\n",
    "def verificar_colunas():\n",
    "    #verificar colunas de uma dos arquivos csv da pasta arquivos_csv\n",
    "    df = pd.read_csv('arquivos_csv/ca-2004-01.csv', sep=';', encoding='latin-1')\n",
    "    #criar lista com as colunas do arquivo\n",
    "    coluna =[col for col in df.columns]\n",
    "    #ler o reestante dos arquivos usando a biblioteca glob e verificar se as colunas são iguais\n",
    "    for arquivo in gb.glob('arquivos_csv/*.csv'):\n",
    "        df = pd.read_csv(arquivo, sep=';', encoding='latin-1')\n",
    "        coluna2 = [col for col in df.columns]\n",
    "        if coluna == coluna2:\n",
    "            print(f'Colunas do arquivo {arquivo} são iguais')\n",
    "        else:\n",
    "            print(f'Colunas do arquivo {arquivo} são diferentes')\n",
    "    #caso as colunas sejam diferentes, mostrar quais são as colunas diferentes\n",
    "    if coluna != coluna2:\n",
    "        print(f'Colunas diferentes: {set(coluna) - set(coluna2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verificar_colunas()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"verificar_colunas()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#remover a primeira coluna de cada arquivo csv\\ndef remover_primeira_coluna():\\n    for arquivo in gb.glob('arquivos_csv/*.csv'):\\n        df = pd.read_csv(arquivo, sep=';', encoding='latin-1')\\n        df.drop(df.columns[0], axis=1, inplace=True)\\n        #mostra o arquivo que foi modificado\\n        print(f'Arquivo {arquivo} modificado')\\n        #salvar o arquivo modificado\\n        df.to_csv(arquivo, sep=';', encoding='latin-1', index=False)\\n        #mostra o arquivo salvo\\n        print(f'Arquivo {arquivo} foi salvo')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remover a primeira coluna de cada arquivo csv\n",
    "def remover_primeira_coluna():\n",
    "    for arquivo in gb.glob('arquivos_csv/*.csv'):\n",
    "        df = pd.read_csv(arquivo, sep=';', encoding='latin-1')\n",
    "        df.drop(df.columns[0], axis=1, inplace=True)\n",
    "        #mostra o arquivo que foi modificado\n",
    "        print(f'Arquivo {arquivo} modificado')\n",
    "        #salvar o arquivo modificado\n",
    "        df.to_csv(arquivo, sep=';', encoding='latin-1', index=False)\n",
    "        #mostra o arquivo salvo\n",
    "        print(f'Arquivo {arquivo} foi salvo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remover_primeira_coluna()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"remover_primeira_coluna()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verificar_colunas()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"verificar_colunas()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar função para concatenar os arquivos csv em um único arquivo\n",
    "def concatenar_arquivos():\n",
    "    #criar lista com os arquivos csv\n",
    "    lista_arquivos = [arquivo for arquivo in gb.glob('arquivos_csv/*.csv')]\n",
    "    #criar dataframe vazio\n",
    "    df = pd.DataFrame()\n",
    "    #loop para ler os arquivos e concatenar em um único dataframe\n",
    "    for arquivo in lista_arquivos:\n",
    "        df = pd.concat([df, pd.read_csv(arquivo, sep=';', encoding='latin-1')])\n",
    "    #salvar o arquivo concatenado\n",
    "    df.to_csv('arquivos_csv/preco_combustiveis_concatenado.csv', sep=';', encoding='utf-8', index=False)\n",
    "    #mostrar o arquivo concatenado\n",
    "    print('Arquivo concatenado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concatenar_arquivos()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''concatenar_arquivos()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para limpar memoria do computador\n",
    "def limpa_memoria():\n",
    "    os.system('clear')\n",
    "limpa_memoria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler o arquivo concatenado\n",
    "def ler_arquivo():\n",
    "    df = pd.read_csv('arquivos_csv/preco_combustiveis_concatenado.csv', sep=';', encoding='latin-1')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arquivos_csv/preco_combustiveis_concatenado.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m ler_arquivo()\n",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m, in \u001b[0;36mler_arquivo\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mler_arquivo\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39marquivos_csv/preco_combustiveis_concatenado.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\tassi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arquivos_csv/preco_combustiveis_concatenado.csv'"
     ]
    }
   ],
   "source": [
    "df = ler_arquivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realizar tratamento de texto usando regex nas colunas Revenda, Municipio, Municipio, Bandeira\n",
    "def tratamento_texto():\n",
    "    # criar lista com as colunas que serão tratadas\n",
    "    colunas = ['Revenda', 'Municipio', 'Bandeira']\n",
    "    # loop para realizar o tratamento de texto\n",
    "    for coluna in colunas:\n",
    "        # remover espaços em branco no inicio e no fim da string\n",
    "        df[coluna] = df[coluna].str.strip()\n",
    "        # remover espaços em branco duplicados\n",
    "        df[coluna] = df[coluna].str.replace(' +', ' ')\n",
    "        # remover acentos\n",
    "        df[coluna] = df[coluna].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "        # remover caracteres especiais\n",
    "        df[coluna] = df[coluna].str.replace('[^a-zA-Z0-9 \\\\\\]', '')\n",
    "        # remover espaços em branco no inicio e no fim da string\n",
    "        df[coluna] = df[coluna].str.strip()\n",
    "        print(f'Coluna {coluna} tratada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratamento_texto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostra a quantidade de linhas e colunas do dataframe\n",
    "print(f'Linhas: {df.shape[0]}')\n",
    "print(f'Colunas: {df.shape[1]}')\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostra os valores nuloes de cada coluna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revover as colunas que não serão utilizadas e retornar um novo dataframe\n",
    "def remover_colunas():\n",
    "    colunas_para_remover = ['Numero Rua', \"Complemento\", \"Bairro\"]\n",
    "    df.drop(colunas_para_remover, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = remover_colunas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_limpo.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['Municipio', 'Revenda', 'CNPJ da Revenda',\n",
    "           'Nome da Rua', 'Cep', 'Produto', 'Data da Coleta', \n",
    "           'Valor de Venda','Unidade de Medida', 'Bandeira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in colunas:\n",
    "    for item in df_limpo[coluna].isnull():\n",
    "        if item == True:\n",
    "            df_limpo.drop(df_limpo[df_limpo[coluna].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_limpo.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = df_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Linhas: {dados.shape[0]}')\n",
    "print(f'Colunas: {dados.shape[1]}')\n",
    "print(dados.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar os valores nulos\n",
    "print(dados.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preencher valores nulos da colunar Valor de Compra com a media dos valores para cada Revenda e Produto\n",
    "def preencher_valores_nulos(df):\n",
    "    df['Valor de Compra'] = df.groupby(['Revenda', 'Produto'])['Valor de Compra'].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar type object das colunas Valor de Venda, Valor de Compra em float\n",
    "def transformar_em_float(coluna):\n",
    "    dados[coluna] = dados[coluna].str.replace(',', '.').astype(float)\n",
    "    return dados\n",
    "colunas = ['Valor de Venda', 'Valor de Compra']\n",
    "for coluna in colunas:\n",
    "    dados = transformar_em_float(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = preencher_valores_nulos(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preencher os valores nulos do valor de compra com 30% a menos do valor de venda\n",
    "def preencher_valores_nulos_nu(df):\n",
    "    df['Valor de Compra'] = df['Valor de Compra'].fillna(df['Valor de Venda'] * 0.7)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = preencher_valores_nulos_nu(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar os tipo das colunas\n",
    "print(df4.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modificar o tipo da coluna Datacoleta para datetime\n",
    "def transformar_em_datetime(df):\n",
    "    df['Data da Coleta'] = pd.to_datetime(df['Data da Coleta'], format='%d/%m/%Y')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = transformar_em_datetime(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renomear a coluna Estado - Sigla para UF\n",
    "def Tratar_colunas(df):\n",
    "    df.rename(columns={'Estado - Sigla': 'uf'}, inplace=True)\n",
    "    #substituir o espaço por _\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = Tratar_colunas(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basedosdados as bd\n",
    "\n",
    "# Para carregar o dado direto no pandas\n",
    "df = bd.read_table(dataset_id='br_anp_precos_combustiveis',\n",
    "table_id='microdados',\n",
    "billing_project_id=\"phrasal-indexer-311822\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar o dataframe em um arquivo csv\n",
    "df.to_csv('arquivos_csv/preco_combustiveis_limpo_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler o arquivo csv\n",
    "df = pd.read_csv('arquivos_csv/preco_combustiveis_limpo_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar os valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preencher valores nulos da colunar preco_compra com 30% a menos do valor de venda\n",
    "def preencher_valores_nulos(df):\n",
    "    df['preco_compra'] = df['preco_compra'].fillna(df['preco_venda'] * 0.7)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preencher_valores_nulos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Exploração / Visualização dos Dados</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística Descritiva\n",
    "\n",
    "# O comando describe retorna parâmetros estatísticos tais como: contagem de linhas, média, desvio \n",
    "# padrão, mínimo, máximo, primeiro, segundo e terceiro quartis.\n",
    "# Deve-se lembrar que este comando só se aplica às variáveis numéricas.\n",
    "\n",
    "df_describe = df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remover a coluna bairro_revenda\n",
    "df.drop('bairro_revenda', axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remover dados nulos de todas as colunas\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar o dataframe em um arquivo csv\n",
    "df.to_csv('arquivos_csv/preco_combustiveis_limpo_v3.csv', index=False, encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///preco_combustiveis.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar dataframe em um arquivo sql\n",
    "df.to_sql('preco_combustiveis', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b791338c3e88062bab114cb03291c948bb196a0ab0843e63e81bf93440029bb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
